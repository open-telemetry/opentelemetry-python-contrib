# Update this with your real OpenAI API key
OPENAI_API_KEY=sk-YOUR_API_KEY

# Uncomment to use Ollama instead of OpenAI
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_API_KEY=unused
# CHAT_MODEL=qwen2.5:0.5b

# Uncomment and change to your OTLP endpoint
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
# OTEL_EXPORTER_OTLP_PROTOCOL=grpc

OTEL_SERVICE_NAME=opentelemetry-python-openai

# Uncomment if your OTLP endpoint doesn't support logs
# OTEL_LOGS_EXPORTER=console

# Remove to hide prompt and completion content
# Possible values (case insensitive):
# - `span_only` - record content on span attibutes
# - `event_only` - record content on event attributes
# - `span_and_event` - record content on both span and event attributes
# - `true` - only used for backward compatibility when
#            `gen_ai_latest_experimental` is not set in the
#            `OTEL_SEMCONV_STABILITY_OPT_IN` environment variable.
# - everything else - don't record content on any signal
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=span_only

# Enables latest and greatest features available in GenAI semantic conventions.
# Note: since conventions are still in development, using this flag would
# likely result in having breaking changes.
#
# Comment out if you want to use semantic conventions of version 1.30.0.
OTEL_SEMCONV_STABILITY_OPT_IN=gen_ai_latest_experimental
