# Update this with your real OpenAI API key
OPENAI_API_KEY=sk-YOUR_API_KEY

# Uncomment to use Ollama instead of OpenAI
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_API_KEY=unused
# CHAT_MODEL=qwen2.5:0.5b

# Uncomment and change to your OTLP endpoint
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
# OTEL_EXPORTER_OTLP_PROTOCOL=grpc

OTEL_SERVICE_NAME=opentelemetry-python-openai

# Remove or change to 'none' to hide prompt and completion content
# Possible values (case insensitive):
# - `span` - record content on span attibutes
# - `event` - record content on event attributes
# - `true` - only used for backward compatibility when 
#            `gen_ai_latest_experimental` is not set in the 
#            `OTEL_SEMCONV_STABILITY_OPT_IN` environemnt variable.
# - everything else - don't record content on any signal
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=span

# Enables latest and greatest features available in GenAI semantic conventions.
# Note: since conventions are still in development, using this flag would
# likely result in having breaking changes. 
#
# Comment out if you want to use semantic conventions of version 1.36.0.
OTEL_SEMCONV_STABILITY_OPT_IN=gen_ai_latest_experimental
